"""
Workflow Module for DeepSense Framework
Matches planner_react_agent flow with dynamic tools, system prompt, model, and API key.
"""

import os
import json
from datetime import datetime
from typing import Dict, Any, List, Optional, TypedDict, Annotated, Sequence, Callable, Union
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI
from langchain_core.messages import (
    HumanMessage, AIMessage, BaseMessage, ToolMessage, SystemMessage
)
from langchain_core.tools import tool
from langchain_core.language_models import BaseChatModel
from deepsense.checkpointer import MongoDBCheckpointer

# Import summarizer_graph - mandatory for chunking
try:
    from deepsense.summarizer_graph import schema_discovery_wrapper
    SUMMARIZER_GRAPH_AVAILABLE = True
except ImportError:
    SUMMARIZER_GRAPH_AVAILABLE = False
    import warnings
    warnings.warn(
        "deepsense.summarizer_graph not available. Chunking functionality will not work properly. "
        "Please ensure summarizer_graph.py is accessible."
    )

# Sandbox tool - predefined in framework
@tool
def sandbox_code_tool(code: str, requirements: list[str] = [], language: str = "python") -> str:
    """
    Runs LLM-generated Python or Node.js code inside an isolated Docker sandbox.
    Supports matplotlib image generation with base64 encoding for markdown display.

    Parameters:
    - code: The source code generated by the language model to execute.
    - requirements: A list of dependencies to install via pip (Python) or npm (Node.js).
    - language: Either 'python' or 'node'.

    Returns:
    - A string combining stdout and stderr from the execution result.
    """
    import requests
    import re
    import base64
    
    sandbox_url = os.getenv("SANDBOX_URL", "http://localhost:8000/run")
    
    try:
        response = requests.post(sandbox_url, json={
            "code": code,
            "requirements": requirements,
            "language": language
        }, timeout=60)
        
        out = response.json()
        stdout = out.get('stdout', '')
        stderr = out.get('stderr', '')
        
        # Extract base64 images from stdout
        image_pattern = r'IMAGE_BASE64:([A-Za-z0-9+/=]+)'
        images = re.findall(image_pattern, stdout)
        clean_stdout = re.sub(image_pattern, '', stdout).strip()
        
        result = f"STDOUT:\n{clean_stdout}"
        if stderr:
            result += f"\nSTDERR:\n{stderr}"
        
        # Process images if any
        if images:
            result += "\n\n## Generated Visualizations:\n\n"
            for i, image_data in enumerate(images):
                try:
                    image_bytes = base64.b64decode(image_data)
                    if image_bytes.startswith(b'\x89PNG\r\n\x1a\n'):
                        result += f"![Generated Visualization {i+1}](data:image/png;base64,{image_data})\n\n"
                except Exception as e:
                    result += f"**Error processing image {i+1}:** {str(e)}\n\n"
        
        return result
    except Exception as e:
        return f"Error executing code: {str(e)}"

# Default system prompt
def get_default_system_prompt() -> str:
    """Get the default system prompt."""
    current_date = datetime.now().strftime("%Y-%m-%d")
    
    return f"""You are an AI agent that can use tools to help users. 

Current date: {current_date}
Capabilities:
- Think step-by-step to solve complex or multi-part problems
- Use available tools to fetch data, run code, or perform tasks
- Execute code securely via the `sandbox_code_tool` tool
- Complete each task either by reasoning directly or by using tools

When a user asks a complex question:
1. Analyze what information is required
2. Break it down into logical sub-tasks
3. Execute each task sequentially
4. Aggregate all results and present a clear, final response

Always follow a step-by-step approach.
Use tools if needed to complete tasks and ensure correctness.
"""

# Agent state definition - matches planner_react_agent
class AgentState(TypedDict):
    """State for the agent workflow - matches planner_react_agent structure."""
    session_id: str
    tool_output: Optional[ToolMessage]
    tool_outputs: Optional[List[ToolMessage]]
    summaries: List[str]
    final_summary: Optional[str]
    messages: Annotated[Sequence[BaseMessage], lambda left, right: left + right]
    tools: List[Dict[str, Any]]
    selected_tools: List[Any]
    bound_model: Any
    tools_bound: bool
    current_tool_index: int
    latest_ai_message: Optional[AIMessage]
    db_store: bool
    user_actions: List[Dict[str, Any]]

class Workflow:
    """
    Workflow class matching planner_react_agent flow.
    Supports dynamic tools, system prompt, model, and API key.
    """
    
    def __init__(
        self,
        checkpointer: Optional[MongoDBCheckpointer] = None,
        llm_model: Optional[str] = None,
        llm_provider: str = "openai",  # "openai", "anthropic", "google"
        api_key: Optional[str] = None,
        system_prompt: Optional[str] = None,
        custom_tools: Optional[List] = None,
        chunking_threshold: int = 15000
    ):
        """
        Initialize the workflow.
        
        Args:
            checkpointer: MongoDB checkpointer instance
            llm_model: Model name (e.g., "gpt-4o", "claude-3-opus")
            llm_provider: LLM provider ("openai", "anthropic", "google")
            api_key: API key for the LLM provider
            system_prompt: Custom system prompt (defaults to built-in)
            custom_tools: Additional tools to add to the workflow
            chunking_threshold: Token threshold for chunking large outputs
        """
        self.checkpointer = checkpointer
        self.llm_model = llm_model or os.getenv("OPENAI_MODEL", "gpt-4o")
        self.llm_provider = llm_provider
        self.api_key = api_key
        self.system_prompt = system_prompt or get_default_system_prompt()
        self.chunking_threshold = chunking_threshold
        
        # Verify summarizer_graph is available (mandatory)
        if not SUMMARIZER_GRAPH_AVAILABLE:
            raise ImportError(
                "deepsense.summarizer_graph is mandatory for workflow chunking functionality. "
                "Please ensure summarizer_graph.py is in the deepsense package."
            )
        
        # Start with sandbox tool (always included)
        self.tools = [sandbox_code_tool]
        
        # Add custom tools if provided
        if custom_tools:
            self.tools.extend(custom_tools)
        
        # Initialize LLM dynamically
        self.llm = self._create_llm()
        
        # Build graph
        self.graph = self._build_graph()
    
    def _create_llm(self) -> BaseChatModel:
        """Create LLM instance based on provider."""
        if self.llm_provider == "openai":
            api_key = self.api_key or os.getenv("OPENAI_API_KEY")
            return ChatOpenAI(
                model=self.llm_model,
                temperature=0,
                openai_api_key=api_key
            )
        elif self.llm_provider == "anthropic":
            from langchain_anthropic import ChatAnthropic
            api_key = self.api_key or os.getenv("ANTHROPIC_API_KEY")
            return ChatAnthropic(
                model=self.llm_model,
                temperature=0,
                anthropic_api_key=api_key
            )
        elif self.llm_provider == "google":
            from langchain_google_genai import ChatGoogleGenerativeAI
            api_key = self.api_key or os.getenv("GEMINI_API_KEY")
            return ChatGoogleGenerativeAI(
                model=self.llm_model,
                temperature=0,
                google_api_key=api_key
            )
        else:
            raise ValueError(f"Unsupported LLM provider: {self.llm_provider}")
    
    def _build_graph(self):
        """Build the LangGraph workflow matching planner_react_agent flow."""
        workflow = StateGraph(AgentState)
        
        # Add nodes matching planner_react_agent
        workflow.add_node("tool_selection", self._tool_selection_node)
        workflow.add_node("model", self._model_node)
        workflow.add_node("router", self._router_node)
        workflow.add_node("tools", self._tool_node_wrapper)
        workflow.add_node("select_tool_output", self._select_tool_output)
        workflow.add_node("discover_schema", self._discover_schema_node)
        workflow.add_node("add_tool_messages", self._add_tool_messages_node)
        
        # Add edges matching planner_react_agent
        workflow.add_edge("tool_selection", "model")
        workflow.add_edge("model", "router")
        workflow.add_conditional_edges(
            "router",
            self._edge_router,
            {
                "tools": "tools",
                "end": END
            }
        )
        workflow.add_edge("tools", "select_tool_output")
        workflow.add_conditional_edges(
            "select_tool_output",
            self._process_tool_output,
            {
                "model": "model",
                "chunking": "discover_schema",
                "normal": "add_tool_messages"
            }
        )
        workflow.add_edge("discover_schema", "select_tool_output")
        workflow.add_edge("add_tool_messages", "select_tool_output")
        workflow.set_entry_point("tool_selection")
        
        # Compile workflow with checkpointer if available
        if self.checkpointer and self.checkpointer.get_saver():
            return workflow.compile(checkpointer=self.checkpointer.get_saver())
        else:
            return workflow.compile()
    
    def _tool_selection_node(self, state: AgentState) -> AgentState:
        """Node that binds all tools to the model."""
        # Bind ALL tools once
        bound_model = self.llm.bind_tools(self.tools)
        
        return {
            "selected_tools": self.tools,
            "bound_model": bound_model,
            "tools_bound": True
        }
    
    def _model_node(self, state: AgentState) -> AgentState:
        """Model node using pre-bound model from state."""
        messages = state["messages"]
        bound_model = state.get("bound_model")
        
        if not bound_model:
            bound_model = self.llm.bind_tools(self.tools)
        
        response = bound_model.invoke(messages)
        
        return {"messages": [response]}
    
    def _router_node(self, state: AgentState) -> AgentState:
        """Router node (placeholder - routing done by edge_router)."""
        return {}
    
    def _edge_router(self, state: AgentState) -> str:
        """Edge router - determines if tools should be used or end."""
        messages = state["messages"]
        last_message = messages[-1] if messages else None
        
        if last_message and hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tools"
        
        # Check for final answer indicators
        if last_message and hasattr(last_message, "content"):
            content_lower = last_message.content.lower()
            if any(phrase in content_lower for phrase in ["final answer", "here is the answer", "summary"]):
                return "end"
        
        return "end"
    
    def _tool_node_wrapper(self, state: AgentState) -> AgentState:
        """Tool node wrapper - executes tools."""
        tool_node = ToolNode(self.tools)
        result = tool_node.invoke(state)
        
        tool_messages = result.get("messages", [])
        tool_outputs = tool_messages if tool_messages else []
        
        return {
            "tool_outputs": tool_outputs,
            "current_tool_index": -1
        }
    
    def _select_tool_output(self, state: AgentState) -> AgentState:
        """Select one tool output at a time."""
        current_tool_index = state.get("current_tool_index", -1)
        tool_outputs = state.get("tool_outputs", [])
        user_actions = state.get("user_actions", [])
        
        current_tool_index += 1
        tool_output = None
        
        if tool_outputs and len(tool_outputs) > current_tool_index:
            tool_output = tool_outputs[current_tool_index]
            
            # Check if this tool output contains a user action
            # This detects user_actions from datasource tools that have user_action=True in their config
            if tool_output and hasattr(tool_output, 'content'):
                try:
                    # Try to parse the content as JSON
                    content_data = json.loads(tool_output.content)
                    
                    # Check if it's a tool response with user_action (from datasources with user_action=True)
                    if isinstance(content_data, dict) and content_data.get("user_action") == True:
                        # This is a user action, add it to user_actions
                        user_actions.append(content_data)
                        print(f"Added user action to user_actions. Total actions: {len(user_actions)}")
                        
                except (json.JSONDecodeError, AttributeError) as e:
                    # Content is not JSON or doesn't have expected structure
                    print(f"Tool output content is not JSON or doesn't have user_action: {e}")
                    pass
        
        # Get latest AI message
        latest_ai_message = None
        messages = state.get("messages", [])
        for msg in reversed(messages):
            if isinstance(msg, AIMessage):
                latest_ai_message = msg
                break
        
        return {
            "tool_output": tool_output,
            "current_tool_index": current_tool_index,
            "latest_ai_message": latest_ai_message,
            "user_actions": user_actions
        }
    
    def _process_tool_output(self, state: AgentState) -> str:
        """Process tool output - decide if chunking needed."""
        tool_output = state.get("tool_output")
        
        if tool_output is None:
            return "model"
        
        # Estimate token count
        try:
            from deepsense.utils.token_utils import estimate_token_count
            data = tool_output.content if hasattr(tool_output, 'content') else str(tool_output)
            token_count = estimate_token_count(data)
            
            if token_count > self.chunking_threshold:
                return "chunking"
            else:
                return "normal"
        except ImportError:
            # Fallback: simple length check
            data = tool_output.content if hasattr(tool_output, 'content') else str(tool_output)
            if len(data) > 50000:  # Rough estimate
                return "chunking"
            else:
                return "normal"
    
    def _discover_schema_node(self, state: AgentState) -> AgentState:
        """
        Schema discovery/chunking node for large outputs.
        Uses summarizer_graph.py (mandatory, just like planner_react_agent.py).
        """
        # Use summarizer_graph (mandatory, same as planner_react_agent.py)
        if not SUMMARIZER_GRAPH_AVAILABLE:
            raise ImportError(
                "deepsense.summarizer_graph is mandatory for chunking. "
                "Please ensure summarizer_graph.py is in the deepsense package."
            )
        
        # Use the schema_discovery_wrapper from summarizer_graph
        return schema_discovery_wrapper(state)
    
    def _add_tool_messages_node(self, state: AgentState) -> AgentState:
        """Add tool messages to conversation."""
        tool_message = state.get("tool_output")
        
        if tool_message is None:
            return {}
        
        return {
            "tool_output": None,
            "messages": [tool_message]
        }
    
    def add_tool(self, tool):
        """Add a tool to the workflow."""
        self.tools.append(tool)
        # Rebuild graph with new tools
        self.graph = self._build_graph()
    
    def invoke(
        self,
        query: str,
        session_id: Optional[str] = None,
        existing_messages: Optional[List[BaseMessage]] = None,
        db_store: bool = True
    ) -> Dict[str, Any]:
        """
        Invoke the workflow with a query.
        
        Args:
            query: User query
            session_id: Optional session/thread ID (used for LangGraph checkpoints)
            existing_messages: Optional existing messages for context
            db_store: Whether to store messages in database
            
        Returns:
            Workflow result
        """
        # Create or get session/thread_id
        if not session_id and self.checkpointer and db_store:
            session_id = self.checkpointer.create_session()
        elif not session_id:
            import uuid
            session_id = str(uuid.uuid4())
        
        # Build messages
        messages = [SystemMessage(content=self.system_prompt)]
        
        if existing_messages:
            messages.extend(existing_messages)
        
        messages.append(HumanMessage(content=query))
        
        # Initialize state matching planner_react_agent
        initial_state = {
            "session_id": session_id,
            "messages": messages,
            "tool_output": None,
            "tool_outputs": None,
            "summaries": [],
            "final_summary": None,
            "tools": [],
            "selected_tools": [],
            "bound_model": None,
            "tools_bound": False,
            "current_tool_index": -1,
            "latest_ai_message": None,
            "db_store": db_store,
            "user_actions": []
        }
        
        # Run workflow with thread_id config for checkpointer
        config = {
            "recursion_limit": 50,
            "configurable": {
                "thread_id": session_id
            }
        }
        
        result = self.graph.invoke(initial_state, config=config)
        
        return result
